{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Difficulty: Beginner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few do's and don'ts on creating Lightweight (containerless*) Kubeflow Pipeline components using `func_to_container_op`.  \n",
    "\\*the pipeline components still run from containers, but you do not need to explicitly create and push these containers somewhere.  Instead, kubeflow uses a base container you specify and runs your code from within that container.  See more detail below\n",
    "\n",
    "**Highlights include:**\n",
    "\n",
    "**General:**\n",
    "* For simple or very iterative tasks, lightweight components may reduce your development burden\n",
    "* Inputs and outputs for Lightweight components are strings by default.  Use the typing package to enable int or float.  More complex data must be serialzed and passed as string (ex: JSON).  Large data should probably be passed as a reference to a file stored elsewhere (eg: minio path, common data store link, etc.)\n",
    "\n",
    "**When code needs helper functions:**\n",
    "* If possible, define all helper functions needed in a pipeline component inside the function itself rather than outside.\n",
    "* If sharing helpers between functions, set `use_code_pickling=True` to automatically pass the helpers with the container functions\n",
    "* **Note:** Apply `use_code_pickling=True` with care, especially if you cannot ensure the python version here in the notebook will be the same as the version in your pipeline container  If you see odd behaviour, it could be this.\n",
    "\n",
    "**When code needs python dependencies:**\n",
    "* When you need dependencies that are already installed on the base image you're running off of, simply `import` them from inside the component function rather than above the code.  This will ensure they're imported at runtime in the pipeline\n",
    "* When you need dependencies that are not installed on the base image, you can pip install them (via `func_to_container_op(packages_to_install=[...])` or by making system calls to pip yourself like [here](https://github.com/kubeflow/pipelines/blob/master/samples/core/lightweight_component/lightweight_component.ipynb)).  This can install packages from anywhere pip can (pypi, github, etc).\n",
    "\n",
    "**Note:** If you're developing code that is well encapsulated across multiple files (eg: my main.py imports from ./utilities.py and ./other_code.py) the easiest way to develop is to push the code to github and then pip install from your github repo in the container (see the github example below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Authoring and Iterating Kubeflow Pipelines using Lightweight Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning applications are often a chain of encapsulated (or encapsulatable) steps.  [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) is a platform for authoring, orchestrating, monitoring, and reusing these pipelines. \n",
    "\n",
    "Pipelines are defined by a directed acyclic graph (DAG) of data/execution flow between components.  At their core, each component is a self-contained set of user code, packaged as a docker container.  They each perform one step in the pipeline, optionally consuming the products of upstream tasks and/or providing results for downstream tasks.  They can be as complex as building a Tensorflow model or as simple as selecting a column from a data file.\n",
    "\n",
    "The typical workflow for building Pipeline Components is:\n",
    "* code up the logic for your component and test it locally.  This could be in python, R, ..., but in the end it needs to work like an executable you could run from a command line\n",
    "* package the code as a docker image and store that container somewhere Kubeflow can find\n",
    "* define a pipeline step that runs that docker container (probably with some command line arguments passed from the pipeline)\n",
    "\n",
    "In addition to this typical workflow of authoring self-contained docker images, there are also several ways to make pipeline steps without explicitly creating a container.  These **[lightweight components](https://www.kubeflow.org/docs/pipelines/sdk/lightweight-python-components/)** automate some of the setup for you to make things easier.  The typical workflow for building lightweight components is:\n",
    "* code up the logic for your component in Python from within the notebook you're defining your pipeline (examples shown later)\n",
    "* define a pipeline step that runs your **python function** from within a generic, base docker container you specify (say the generic [tensorflow container](https://hub.docker.com/r/tensorflow/tensorflow/tags))\n",
    "\n",
    "Although this approach has limits, it may enable easier authoring and iterating on pipeline components because you don't need to rebuild your docker image each time.  This demo shows a few examples of these workflows, along with their limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Settings\n",
    "\n",
    "(modify these for your own use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the experiment that all pipeline runs will be nested in on\n",
    "# https://kubeflow.covid.cloud.statcan.ca/_/pipeline/#/experiments\n",
    "experiment_name = \"demo-kfp-lightweight-components\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings\n",
    "\n",
    "(likely can leave these alone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a base image to be used in generating component ops from python functions.\n",
    "# kfp uses this image to run a python session for the component func_to_container_op\n",
    "# This uses a generic python image, but you can use whichever one provides the best \n",
    "# starting point for your code (generally an image that has everything dependency \n",
    "# you need preinstalled, but not much else.  For example, if you're building \n",
    "# tensorflow models, you should probably start with tensorflow preinstalled, such as\n",
    "# a tensorflow base image)\n",
    "BASE_IMAGE = \"python:3.8.3-buster\"\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import func_to_container_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Components from Self-Contained Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kubeflow Pipeline function `func_to_container_op` lets you turn a generic python function into a full pipeline component.  To do this, behind the scenes Kubeflow Pipelines effectively rewrites your function as a script to be run from within the base image you provide (the base image is defined as an argument to `func_to_container_op` as seen below).  \n",
    "\n",
    "For simple, self contained python code, this is an effective way to define Pipeline Components quickly.  For example, we can define a pipeline step that accepts two strings and concatenates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a base python function that contains all the logic of our single pipeline step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_string(a, b) -> str:\n",
    "    return f\"({a} | {b})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing locally to make sure it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(String 1 | String 2)\n"
     ]
    }
   ],
   "source": [
    "# Test locally\n",
    "print(concat_string(\"String 1\", \"String 2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now converting this from a python function to a kubeflow component factory (a function that can be used to define instances of this particular type of pipeline component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_string_component = func_to_container_op(concat_string,\n",
    "                                               base_image=BASE_IMAGE\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we define our Pipeline as a function that uses our component(s), decorated by the dsl.pipeline decorator.  In this case, we have two concat_string_components, one that concatenates str1+str2, and another that concatenates (str1+str2) with str3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"This one keeps it nice and simple\",\n",
    ")\n",
    "def pipeline(str1, str2, str3):\n",
    "    # Note that we use the concat_string_component, not the\n",
    "    # original concat_string() function\n",
    "    concat_result_1 = concat_string_component(str1, str2)\n",
    "\n",
    "    # By using cancat_result_1's output, we define the dependency of\n",
    "    # concat_result_2 on concat_result_1\n",
    "    concat_result_2 = concat_string_component(concat_result_1.output, str3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can submit our pipeline from code with arguments like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/4e57e037-850b-4cbf-9e15-f077a5ecf137\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=4e57e037-850b-4cbf-9e15-f077a5ecf137)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'str1': 'String 1', 'str2': 'String 2', 'str3': 'String 3'},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which produces the pipeline and output:\n",
    "\n",
    "![Simple pipeline](images/demo_kfp_lightweight_components_pipeline1_complete.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that what happens here is the `kfp.Client().create_run_from_pipeline_func` is taking our `pipeline()` we defined and translating it into a pipeline definition (`pipeline.yaml.zip`) that it then passes to Kubeflow Pipelines to actually run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow is great for very simple actions.  For something less trivial, however, we often have dependencies on helper functions or packages..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Components that need Dependencies or Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What not to do with dependencies and helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Care is required whenever a pipeline component defined using `create_run_from_pipeline_func` requires anything outside the code written directly in the wrapped function.  Common gotchas include:\n",
    "\n",
    "* defining helper functions outside the pipeline component\n",
    "* using packages in the pipeline component without importing them, or importing packages that are not installed in the base image at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, while it runs fine locally, this function that depends on a helper will fail in a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sum_helper(*numbers):\n",
    "    total = 0\n",
    "    for x in numbers:\n",
    "        total += x\n",
    "    return total\n",
    "\n",
    "\n",
    "# Note: Arguments for components created with func_to_container_op expect string\n",
    "# To enable float or int types, use type hinting.  For more complex inputs,\n",
    "# serialize with JSON or store data to a location and pass the path\n",
    "def my_sum(a: float, b: float, c: float) -> float:\n",
    "    \"\"\"\n",
    "    A function that sums its numeric arguments\n",
    "    \"\"\"\n",
    "    return my_sum_helper(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(my_sum(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sum_component = func_to_container_op(my_sum,\n",
    "                                        base_image=BASE_IMAGE\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But not here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"This one is a bit more complicated and fails\",\n",
    ")\n",
    "def pipeline(a, b, c):\n",
    "    sum_result = my_sum_component(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/97ed2104-8a26-412c-ae0c-f02c624174f1\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=97ed2104-8a26-412c-ae0c-f02c624174f1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'a': 1.0, 'b': 2.0, 'c': 3.0},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "![Simple pipeline](images/demo_kfp_lightweight_components_pipeline_with_helper_my_sum_failed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, this function that depends on the json package will also work locally but fail in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def sum_via_json(numbers_as_json):\n",
    "    \"\"\"\n",
    "    A summation function that sums a list of numbers defined as a JSON string\n",
    "\n",
    "    Output is returned as a JSON formatted string (which is really just \n",
    "    str(number), but still...)\n",
    "    \"\"\"\n",
    "    numbers = json.loads(numbers_as_json)\n",
    "    summed = sum(numbers)\n",
    "    return json.dumps(summed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing locally works great:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = 6\n"
     ]
    }
   ],
   "source": [
    "numbers_as_json = json.dumps([1, 2, 3])\n",
    "result_as_json = sum_via_json(numbers_as_json)\n",
    "result = json.loads(result_as_json)\n",
    "print(f\"result = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But running through a pipeline does not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_via_json_component = func_to_container_op(sum_via_json,\n",
    "                                              base_image=BASE_IMAGE\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"This one is a bit more complicated and fails\",\n",
    ")\n",
    "def pipeline(numbers_as_json):\n",
    "    sum_result = sum_via_json_component(numbers_as_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/d389b3db-bf21-4955-afd5-d5991d95a467\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=d389b3db-bf21-4955-afd5-d5991d95a467)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'numbers_as_json': [1, 2, 3]},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "![Simple pipeline](images/demo_kfp_lightweight_components_pipeline_with_dependency_failed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to handle dependencies and helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For helpers, they can be defined within the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Arguments for components created with func_to_container_op expect string\n",
    "# To enable float or int types, use type hinting.  For more complex inputs,\n",
    "# serialize with JSON or store data to a location and pass the path\n",
    "def my_sum_internal_helper(a: float, b: float, c: float) -> float:\n",
    "    \"\"\"\n",
    "    A function that sums its numeric arguments\n",
    "    \"\"\"\n",
    "    def my_sum_helper(*numbers):\n",
    "        total = 0\n",
    "        for x in numbers:\n",
    "            total += x\n",
    "        return total\n",
    "\n",
    "    return my_sum_helper(a, b, c)\n",
    "\n",
    "\n",
    "my_sum_internal_helper_component = func_to_container_op(my_sum_internal_helper,\n",
    "                                                        base_image=BASE_IMAGE\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, they can be defined outside the helper and pickled with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sum_helper(*numbers):\n",
    "    total = 0\n",
    "    for x in numbers:\n",
    "        total += x\n",
    "    return total\n",
    "\n",
    "\n",
    "def my_sum_external_helper(a: float, b: float, c: float) -> float:\n",
    "    \"\"\"\n",
    "    A function that sums its numeric arguments\n",
    "    \"\"\"\n",
    "    return my_sum_helper(a, b, c)\n",
    "\n",
    "\n",
    "# NOTE the extra argument here\n",
    "my_sum_external_helper_component = func_to_container_op(my_sum_external_helper,\n",
    "                                                        base_image=BASE_IMAGE,\n",
    "                                                        use_code_pickling=True,  # <----\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code pickling will wrap up simple helper functions with the code.  Docs suggest it can do more, but initial testing couldn't get that to work (anyone who gets packages or complex imports working through use_code_pickling should let us know!)\n",
    "\n",
    "Code pickling can have some downsides (mainly related to python version differences between where it is picked and where it is executed).  If you don't need it, you should probably leave it off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"This one is a bit more complicated, but works!\",\n",
    ")\n",
    "def pipeline(a, b, c):\n",
    "    sum_result_internal = my_sum_internal_helper_component(a, b, c)\n",
    "    sum_result_external = my_sum_external_helper_component(a, b, c)\n",
    "    final_sum = my_sum_internal_helper_component(sum_result_internal.output,\n",
    "                                                 sum_result_external.output,\n",
    "                                                 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/32442e8b-0252-445d-98e9-aa8d94eb72ed\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=32442e8b-0252-445d-98e9-aa8d94eb72ed)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'a': 1.0, 'b': 2.0, 'c': 3.0},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working pipeline! \n",
    "\n",
    "![Working pipeline](images/demo_kfp_lightweight_components_pipeline_with_helper_my_sum_successful.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dependencies, several options exist depending on whether the package you want is already installed on the base image.\n",
    "\n",
    "If the package you want is installed on the image, you can simply `import` it from within your pipeline component.  Revisiting the JSON example from above, this will work (because JSON is available on BASE_IMAGE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_via_json(numbers_as_json: str) -> str:\n",
    "    \"\"\"\n",
    "    A summation function that sums a list of numbers defined as a JSON string\n",
    "\n",
    "    Output is returned as a JSON formatted string (which is really just \n",
    "    str(number), but still...)\n",
    "    \"\"\"\n",
    "    # Import necessary libraries inside the function, as the only code written\n",
    "    # in the pipeline component's function will be executed by the pipeline\n",
    "    # (plus some wrapper material KFP creates for you)\n",
    "    import json\n",
    "    numbers = json.loads(numbers_as_json)\n",
    "    summed = sum(numbers)\n",
    "    return json.dumps(summed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing locally works great:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = 6\n"
     ]
    }
   ],
   "source": [
    "numbers_as_json = json.dumps([1, 2, 3])\n",
    "result_as_json = sum_via_json(numbers_as_json)\n",
    "result = json.loads(result_as_json)\n",
    "print(f\"result = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_via_json_component = func_to_container_op(sum_via_json,\n",
    "                                              base_image=BASE_IMAGE\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the package we need is not available on the base image, we can either install it [ourselves](https://github.com/kubeflow/pipelines/blob/master/samples/core/lightweight_component/lightweight_component.ipynb) or use func_to_container_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: delorean==1.0.0 in /opt/conda/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /opt/conda/lib/python3.7/site-packages (from delorean==1.0.0) (2.0.0)\n",
      "Requirement already satisfied: babel>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from delorean==1.0.0) (2.8.0)\n",
      "Requirement already satisfied: humanize>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from delorean==1.0.0) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from delorean==1.0.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2015.7 in /opt/conda/lib/python3.7/site-packages (from delorean==1.0.0) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.4.2->delorean==1.0.0) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# pip install here so we can test locally, but this has no effect on the\n",
    "# pipeline component at pipeline runtime\n",
    "!pip install delorean==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_with_pip_installed_package(json_string):\n",
    "    import delorean\n",
    "    return json_string + \" | \" + str(delorean.Delorean(timezone=\"US/Eastern\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"some string, could be json | Delorean(datetime=datetime.datetime(2020, 5, 28, 15, 54, 13, 463352), timezone='US/Eastern')\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotate_with_pip_installed_package(\"some string, could be json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And turning this into a component factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add string list of package names exactly how you'd pass\n",
    "# them to pip, with or without version\n",
    "packages_to_install = ['delorean==1.0.0']\n",
    "annotate_with_pip_installed_package_component = func_to_container_op(annotate_with_pip_installed_package,\n",
    "                                              base_image=BASE_IMAGE,\n",
    "                                              packages_to_install=packages_to_install,  # <---\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"This one keeps it nice and simple\",\n",
    ")\n",
    "def pipeline(numbers_as_json):\n",
    "    sum_result = sum_via_json_component(numbers_as_json)\n",
    "    annotated_result = annotate_with_pip_installed_package_component(sum_result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/4a8e2765-6c09-4fe1-913b-2617604894c3\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=4a8e2765-6c09-4fe1-913b-2617604894c3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'numbers_as_json': json.dumps([1, 2, 3])},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see everything works!\n",
    "\n",
    "![everything works!](images/demo_kfp_lightweight_components_pipeline_with_dependencies_successful.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative development using your own code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dependencies using your own code, one way to quickly iterate is by pushing your code to git and then installing it in the pipeline component every iteration.  For example, say we were locally iterating on this [project](https://github.com/ca-scribner/lrl).  We could do our development, push the code, and then use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install here is local only.  This enables local testing but doesn't help\n",
    "# the pipeline\n",
    "# !pip install git+https://github.com/ca-scribner/lrl\n",
    "\n",
    "# We leave it commented here to show how testing the pipeline step locally \n",
    "# will fail, but running in the pipeline with kfp installing your packages\n",
    "# for you will succeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_step(something_just_because: str) -> str:\n",
    "    import lrl\n",
    "    rt = lrl.environments.get_racetrack(track='20x10_U',\n",
    "                             x_vel_limits=(-2, 2),\n",
    "                             y_vel_limits=(-2, 2),\n",
    "                             x_accel_limits=(-2, 2),\n",
    "                             y_accel_limits=(-2, 2),\n",
    "                             max_total_accel=2,\n",
    "                             )\n",
    "\n",
    "    # Return a list of strings that looks like:\n",
    "    # ['GGGGGGGGGGGGGGGGGGGG',\n",
    "    #  'GGGGGGGGGGGGGGGGGGGG',\n",
    "    #  'GGG     OOOO      GG',\n",
    "    #  'GGG     GGGG      GG',\n",
    "    #  'GGOOOOGGGGGGGGOOOOGG',\n",
    "    #  'GGOOOGGGGGGGGGGOOOGG',\n",
    "    #  'GG    GGGGGGGG    GG',\n",
    "    #  'GG      SGGGGG    GG',\n",
    "    #  'GGGGGGGGGGGGGGFFFFGG',\n",
    "    #  'GGGGGGGGGGGGGGFFFFGG']\n",
    "    # (converted to a string, as lightweight component needs)\n",
    "    return str(rt.track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lrl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b2ed3a6dab2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-cac930263fbb>\u001b[0m in \u001b[0;36mpipeline_step\u001b[0;34m(something_just_because)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpipeline_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msomething_just_because\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mlrl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     rt = lrl.environments.get_racetrack(track='20x10_U',\n\u001b[1;32m      4\u001b[0m                              \u001b[0mx_vel_limits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0my_vel_limits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lrl'"
     ]
    }
   ],
   "source": [
    "pipeline_step('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add string list of package names exactly how you'd pass\n",
    "# them to pip, with or without version\n",
    "packages_to_install = ['git+https://github.com/ca-scribner/lrl']\n",
    "pipeline_component = func_to_container_op(pipeline_step,\n",
    "                                              base_image=BASE_IMAGE,\n",
    "                                              packages_to_install=packages_to_install,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"This one keeps it nice and simple\",\n",
    ")\n",
    "def pipeline(some_arg):\n",
    "    result = pipeline_component(some_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/0d7a573f-9c21-4a1c-9f26-304e695af40d\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=0d7a573f-9c21-4a1c-9f26-304e695af40d)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'some_arg': \"I am not very important\"},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Pipeline runs successfully, but not shown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight components with integer inputs and multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import happens outside the function because it is used to \n",
    "# DEFINE the function, not as something inside the function\n",
    "from typing import NamedTuple\n",
    "\n",
    "def funky_divide(dividend: float, divisor: float) -> NamedTuple(\"funky_divide_output\", [('quotient', float), ('remainder', float), ('as_string', str)]):\n",
    "    \"\"\"\n",
    "    Returns a tuple of (dividend // divisor, dividend % divisor)\n",
    "    \n",
    "    Note that we use type hints to tell func_to_container_op that:\n",
    "    - our inputs are floats, not strings\n",
    "    - our output has several parts, each with their own type\n",
    "    \"\"\"\n",
    "    quotient = dividend // divisor\n",
    "    remainder = dividend % divisor\n",
    "    as_string = f\"{quotient} and {remainder}/{divisor}\"\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    # Define the namedtuple's structure\n",
    "    output = namedtuple(\"funky_divide_output\", [\"quotient\", \"remainder\", \"as_string\"])\n",
    "    my_output = output(quotient, remainder, as_string)\n",
    "    return my_output\n",
    "    \n",
    "funky_divide_op_factory = func_to_container_op(funky_divide, \n",
    "                                               base_image=BASE_IMAGE\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funky_divide_output(quotient=1, remainder=2, as_string='1 and 2/3')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funky_divide(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"My demo-kfp-lightweight-components pipeline\",\n",
    "    description=\"Now we've got lots of fun complications!\",\n",
    ")\n",
    "def pipeline(x, y):\n",
    "#     res = my_divmod(x, y)\n",
    "    funky_divide_1 = funky_divide_op_factory(x, y)\n",
    "    \n",
    "    # Now divide the quotient from _1 by the remainder from _1\n",
    "    funky_divide_2 = funky_divide_op_factory(funky_divide_1.outputs['quotient'], funky_divide_1.outputs['remainder'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f186bcfa-2ca2-43e6-84e5-d4a4a89a9516\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/1f7a8710-0871-4766-9c40-49d61ea4cf66\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=1f7a8710-0871-4766-9c40-49d61ea4cf66)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfp.Client().create_run_from_pipeline_func(\n",
    "    pipeline,\n",
    "    arguments={'x': 10., 'y': 4.},\n",
    "    experiment_name=experiment_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This example shows basic metadata tracking using Kubeflow Metadata.  This allows for artifacts (datasets, models, metrics) and executions (training runs, deployments) to be browsed in the Lineage Tracker and to allow for better traceability of how models and data relate.  \n",
    "\n",
    "![title](images/artifact_explorer_lineage_explorer.png)\n",
    "\n",
    "More details are available [here](https://www.kubeflow.org/docs/components/metadata/#learn-more-about-the-metadata-sdk).  This notebook is based on [this demo](https://github.com/kubeflow/metadata/blob/master/sdk/python/sample/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you get errors about tensorflow estimator components or modules not being available, try:\n",
    "```\n",
    "pip uninstall kubeflow-metadata tensorflow-estimator\n",
    "pip install tensorflow-estimator==2.3.0 kubeflow-metadata\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:20.163793Z",
     "iopub.status.busy": "2020-08-30T15:21:20.163582Z",
     "iopub.status.idle": "2020-08-30T15:21:24.973175Z",
     "shell.execute_reply": "2020-08-30T15:21:24.972227Z",
     "shell.execute_reply.started": "2020-08-30T15:21:20.163768Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from kubeflow.metadata import metadata\n",
    "from datetime import datetime\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "source": [
    "# Settings\n",
    "\n",
    "(you do not need to change these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:24.974571Z",
     "iopub.status.busy": "2020-08-30T15:21:24.974352Z",
     "iopub.status.idle": "2020-08-30T15:21:24.977774Z",
     "shell.execute_reply": "2020-08-30T15:21:24.977182Z",
     "shell.execute_reply.started": "2020-08-30T15:21:24.974545Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Should we include this in all environments as an environment variable?\n",
    "# (these are defaults of Kubeflow Metadata gRPC serivce)\n",
    "METADATA_STORE_HOST = \"metadata-grpc-service.kubeflow\"\n",
    "METADATA_STORE_PORT = 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing metadata in kubeflow.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubeflow Metadata works around [these five key objects](https://www.kubeflow.org/docs/components/metadata/#learn-more-about-the-metadata-sdk), three describing data and two describing contexts:\n",
    "\n",
    "* Data\n",
    "    * DataSet to capture metadata for a dataset that forms the input into or the output of a component in your workflow\n",
    "    * Metrics to capture metadata for the metrics used to evaluate an ML model\n",
    "    * Model to capture metadata for an ML model that your workflow produces\n",
    "\n",
    "* Context\n",
    "    * Execution to capture metadata for an execution (run) of your ML workflow, which might use or produce one or more Data objects\n",
    "    * Workspace to group many objects related to a specific task\n",
    "    \n",
    "For example, a ML training `Execution` might be run using two input `DataSet`s (say ds_train and ds_validate) and produce a `Model` (model), some scoring `Metric`s, and a `DataSet` of results for the validation data.  A second deployment `Execution` might then be run using an input `Dataset` (ds_test) and the previous `Model`, producing some deployment `Metric`s (execution time, score on ds_test, etc.).  Both of these might be part of the same train-and-deploy-myModel `Workspace`.  Samples of how to achieve this are shown below.\n",
    "\n",
    "Behind the scenes, kubeflow.metadata takes advantage of [ml-metadata](https://www.tensorflow.org/tfx/guide/mlmd) (mlmd), a generic implementation of a metadata store.  kubeflow.metadata classes wrap mlmd for convenience and to apply some conventions (for example, defining a `type` for each artifact type, like `kubeflow.org/alpha/data_set` for `DataSet`).  As seen below, sometimes we need to interact directly with the mlmd store when kubeflow.metadata does not offer convenience functions for what we want to do.  \n",
    "\n",
    "kubeflow.metadata uses the `Workspace` object as its manager of the mlmd store, so we generally interact with the store through a `Workspace`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:24.978777Z",
     "iopub.status.busy": "2020-08-30T15:21:24.978600Z",
     "iopub.status.idle": "2020-08-30T15:21:25.062177Z",
     "shell.execute_reply": "2020-08-30T15:21:25.061309Z",
     "shell.execute_reply.started": "2020-08-30T15:21:24.978755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note this will by default either return an existing workspace of this name,\n",
    "# or create a new one if it does not exist\n",
    "ws = metadata.Workspace(\n",
    "    store=metadata.Store(grpc_host=METADATA_STORE_HOST,\n",
    "                         grpc_port=METADATA_STORE_PORT),\n",
    "    name=\"kubeflow-metadata-demo-workspace\",\n",
    "    description=\"a workspace for testing and demos\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a run in a workspace\n",
    "\n",
    "(these are optional and entirely sure what they're needed for.  Seems to be an additional sub context we can use within workspaces for more organization?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.063848Z",
     "iopub.status.busy": "2020-08-30T15:21:25.063619Z",
     "iopub.status.idle": "2020-08-30T15:21:25.067998Z",
     "shell.execute_reply": "2020-08-30T15:21:25.067206Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.063822Z"
    }
   },
   "outputs": [],
   "source": [
    "r = metadata.Run(\n",
    "    workspace=ws,\n",
    "    name=\"run-\" + datetime.utcnow().isoformat(\"T\"),\n",
    "    description=\"a run in our test workspace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an execution in a run\n",
    "\n",
    "Unlike Workspaces, executions created like this will always be unique, even if they have the same name.  Try creating one twice here (but make sure to use the same name twice, don't just rerun this block as the timestamp in the name will change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.069326Z",
     "iopub.status.busy": "2020-08-30T15:21:25.069035Z",
     "iopub.status.idle": "2020-08-30T15:21:25.111183Z",
     "shell.execute_reply": "2020-08-30T15:21:25.110362Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.069299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An execution execution-training-2020-08-30T15:21:25.079321 was created with id 79\n"
     ]
    }
   ],
   "source": [
    "name = \"execution-training-\" + datetime.utcnow().isoformat(\"T\")\n",
    "ex = metadata.Execution(\n",
    "    name=name,\n",
    "    workspace=ws,\n",
    "    run=r,  # Optional\n",
    "    description=\"an example training execution\"\n",
    ")\n",
    "print(f\"An execution {ex.name} was created with id {ex.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a DataSet and log it to an Execution\n",
    "\n",
    "The kubeflow.metadata wrappers provide some convenience functionality around committing and reusuing `DataSet`s.  To log a `DataSet`, we instantiate a `metadata.DataSet` object, and then `log()` it to a `Workspace`.  The `log` functions check if this `DataSet` already exists in the store before committing, returning the existing `DataSet` if it exists otherwise returning the newly committed `DataSet`.  `DataSet`s are keyed by (`name`, `uri`, `version`) - if all three match another object in the store, we reuse that object.  This lets us use the same `DataSet` for multiple executions and track lineage.\n",
    "\n",
    "Note that a fresh `metadata.DataSet` does not have an `id` until it has been `log`ged into the `Workspace.store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.113826Z",
     "iopub.status.busy": "2020-08-30T15:21:25.113602Z",
     "iopub.status.idle": "2020-08-30T15:21:25.118137Z",
     "shell.execute_reply": "2020-08-30T15:21:25.117475Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.113801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet my-input-data with id None\n"
     ]
    }
   ],
   "source": [
    "ds_input = metadata.DataSet(\n",
    "    description=\"example input data\",\n",
    "    name=\"my-input-data\",\n",
    "    uri=\"my-minio-path/to-my/data.csv\",\n",
    "    version=\"12345.67890\",  # This could be a hash of the data, ensuring data\n",
    "                            # is exactly as expected\n",
    "    query=\"SELECT * from data\",  # Optional documentation of query\n",
    ")\n",
    "print(f\"DataSet {ds_input.name} with id {ds_input.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.142798Z",
     "iopub.status.busy": "2020-08-30T15:21:25.142457Z",
     "iopub.status.idle": "2020-08-30T15:21:25.165410Z",
     "shell.execute_reply": "2020-08-30T15:21:25.164661Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.142755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(via ds_input): DataSet my-input-data with id 125\n",
      "(via ds_returned): DataSet my-input-data with id 125\n"
     ]
    }
   ],
   "source": [
    "ds_returned = ex.log_input(ds_input)\n",
    "print(f\"(via ds_input): DataSet {ds_input.name} with id {ds_input.id}\")\n",
    "print(f\"(via ds_returned): DataSet {ds_returned.name} with id {ds_returned.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we create a new DataSet with the same details as above and log it to `ex` (or any other object), we will reuse the existing DataSet (as seen by the ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.166650Z",
     "iopub.status.busy": "2020-08-30T15:21:25.166443Z",
     "iopub.status.idle": "2020-08-30T15:21:25.187719Z",
     "shell.execute_reply": "2020-08-30T15:21:25.187020Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.166625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(before .log_input()): DataSet my-input-data with id  None\n",
      "(after .log_input()):  DataSet my-input-data with id  125\n"
     ]
    }
   ],
   "source": [
    "ds_input_duplicated = metadata.DataSet(\n",
    "    description=\"this_changed_but_doesn't_matter_for_duplication\",\n",
    "    name=\"my-input-data\",\n",
    "    uri=\"my-minio-path/to-my/data.csv\",\n",
    "    version=\"12345.67890\",\n",
    "    query=\"this_changed_but_doesn't_matter_for_duplication\",\n",
    ")\n",
    "print(f\"(before .log_input()): DataSet {ds_input_duplicated.name} with id \"\n",
    "      f\" {ds_input_duplicated.id}\")\n",
    "ds_returned = ex.log_input(ds_input_duplicated)\n",
    "print(f\"(after .log_input()):  DataSet {ds_input_duplicated.name} with id \"\n",
    "      f\" {ds_input_duplicated.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: while we are reusing the same `DataSet` when logging, it might still be linking the dataset multiple times to the `Execution` (in the Kubeflow Artifacts UI we can see multiple associations between the same `DataSet` and `Execution`.  Maybe a bug?  This is only a problem if we have a possibility of logging the same `DataSet` to the same `Execution` multiple times though - easy to do in our example here, but not common in practice since each `Execution` is probably a pipeline run or training event. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log a model as output\n",
    "\n",
    "`Model`s are logged similar to `DataSet`s.  `Model`s also have the same logic for duplication - logging a model with the same (`uri`, `name`, `version`) as another in the store will **reuse** the existing model rather than create a new one.  `Model` objects have additional optional metadata that can be stored on them, such as model_type or hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.188798Z",
     "iopub.status.busy": "2020-08-30T15:21:25.188602Z",
     "iopub.status.idle": "2020-08-30T15:21:25.286227Z",
     "shell.execute_reply": "2020-08-30T15:21:25.285412Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.188774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(before .log_output()): Model myModel with id None\n",
      "(after .log_output()):  Model myModel with id 127\n"
     ]
    }
   ],
   "source": [
    "# uuid4 just gives us a unique model version.  This could be a kubeflow\n",
    "# pipeline run_id, a timestamp (if you know it will be unique), etc\n",
    "model_version = \"model_version_\" + str(uuid4())\n",
    "model = metadata.Model(\n",
    "    name=\"myModel\",\n",
    "    uri=\"minio/path/to/my/model.pkl.gz\",\n",
    "    version=model_version,\n",
    "    description=\"a sample model\",\n",
    "    model_type=\"neural network\",\n",
    "    training_framework={\n",
    "        \"name\": \"tensorflow\",\n",
    "        \"version\": \"v1.0\",\n",
    "    },\n",
    "    hyperparameters={\n",
    "        \"learning_rate\": 0.5,\n",
    "        \"layers\": [10, 3, 1],\n",
    "        \"early_stop\": True,\n",
    "    },\n",
    ")\n",
    "print(f\"(before .log_output()): Model {model.name} with id {model.id}\")\n",
    "model = ex.log_output(model)\n",
    "print(f\"(after .log_output()):  Model {model.name} with id {model.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Metadata for serving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of how you could later make an execution for serving, and refer to an existing model that's already in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.287523Z",
     "iopub.status.busy": "2020-08-30T15:21:25.287275Z",
     "iopub.status.idle": "2020-08-30T15:21:25.336749Z",
     "shell.execute_reply": "2020-08-30T15:21:25.335929Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.287493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the model with id 127 and version 'model_version_aaa7f115-edcd-4a87-8b6a-426d8c88ceda'.\n"
     ]
    }
   ],
   "source": [
    "serving_application = metadata.Execution(\n",
    "    name=\"serving model\",\n",
    "    workspace=ws,\n",
    "    description=\"an execution to represent model serving component\",\n",
    ")\n",
    "# Noticed we use model name, version, uri to uniquely identify existing model.\n",
    "served_model = metadata.Model(\n",
    "    name=\"myModel\",\n",
    "    uri=\"minio/path/to/my/model.pkl.gz\",\n",
    "    version=model.version,  # Reusing the model version from above\n",
    ")\n",
    "m = serving_application.log_input(served_model)\n",
    "print(\"Found the model with id {0.id} and version '{0.version}'.\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lineage tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've logged some artifacts and executions into the store, go to the [Artifacts](https://kubeflow.covid.cloud.statcan.ca/_/pipeline/#/artifacts) or [Executions](https://kubeflow.covid.cloud.statcan.ca/_/pipeline/#/executions) UI's and check them out.  From there you can see all the \n",
    "\n",
    "TODO: `Execution`s created by kubeflow.metadata don't show up well in the Execution page.  See [this issue](https://github.com/StatCan/daaas/issues/215) for details.  They're still accessible via the Lineage Explorer or API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of accessing metadata by API is shown below.  This requires us to interact directly with the `mlmd.Store` object.  Note that this `Store` has other access methods, such as `get_artifacts_by_context()`, etc. \n",
    "\n",
    "TODO: Build convenience functions to make this more direct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all executions (eg: trainings or deployments) that use a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.337982Z",
     "iopub.status.busy": "2020-08-30T15:21:25.337775Z",
     "iopub.status.idle": "2020-08-30T15:21:25.344837Z",
     "shell.execute_reply": "2020-08-30T15:21:25.344038Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.337957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find Model id is 127\n",
      "\n",
      "All executions related to the model are {80, 79}\n"
     ]
    }
   ],
   "source": [
    "print(\"Find Model id is %s\\n\" % model.id)\n",
    "model_events = ws.store.get_events_by_artifact_ids([model.id])\n",
    "\n",
    "execution_ids = set(e.execution_id for e in model_events)\n",
    "print(\"All executions related to the model are {}\".format(execution_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all artifacts associated with a particular training event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-30T15:21:25.346135Z",
     "iopub.status.busy": "2020-08-30T15:21:25.345935Z",
     "iopub.status.idle": "2020-08-30T15:21:25.359232Z",
     "shell.execute_reply": "2020-08-30T15:21:25.358501Z",
     "shell.execute_reply.started": "2020-08-30T15:21:25.346110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All artifacts related to the training event are {125, 127}\n"
     ]
    }
   ],
   "source": [
    "trainer_events = ws.store.get_events_by_execution_ids([ex.id])\n",
    "artifact_ids = set(e.artifact_id for e in trainer_events)\n",
    "print(f\"All artifacts related to the training event are {artifact_ids}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
